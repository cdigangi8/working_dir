{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relax and hold Steady part 4\n",
    "\n",
    "Test Problem!\n",
    "\n",
    "Poisson:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla^2 p = -2\\left(\\frac{\\pi}{2}\\right)^2\\sin\\left( \\frac{\\pi x}{L} \\right) \\cos\\left(\\frac{\\pi y}{L}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "in domain:\n",
    "\n",
    "$$\\left\\lbrace \\begin{align*}\n",
    "0 &\\leq x\\leq 1  \\\\\n",
    "-0.5 &\\leq y \\leq 0.5 \n",
    "\\end{align*} \\right.$$\n",
    "\n",
    "with BCs\n",
    "\n",
    "$$p=0 \\text{ at } \\left\\lbrace \n",
    "\\begin{align*}\n",
    "x&=0\\\\\n",
    "y&=0\\\\\n",
    "y&=-0.5\\\\\n",
    "y&=0.5\n",
    "\\end{align*} \\right.$$\n",
    "\n",
    "Assum initial state p=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theory\n",
    "\n",
    "Discretized Poisson\n",
    "\n",
    "$$\\frac{p_{i+1,j}^{k}-2p_{i,j}^{k}+p_{i-1,j}^{k}}{\\Delta x^2}+\\frac{p_{i,j+1}^{k}-2 p_{i,j}^{k}+p_{i,j-1}^{k}}{\\Delta y^2}=b_{i,j}^{k}$$\n",
    "\n",
    "symbollically written:\n",
    "\n",
    "\\begin{equation}\n",
    "A{\\bf p}={\\bf b}\n",
    "\\end{equation}\n",
    "\n",
    "where $A$ is a $N\\times N$ matrix.\n",
    "\n",
    "Define iteration of potential:\n",
    "\n",
    "\\begin{equation}\n",
    "{\\bf p}^{k+1}={\\bf p}^k + \\alpha {\\bf d}^k\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume solution exists to poisson\n",
    "\n",
    "\\begin{equation}\n",
    "A \\bf p = b\n",
    "\\end{equation}\n",
    "\n",
    "The error at any point $i$ is the difference between the calculated value and the exact solution:\n",
    "\n",
    "\\begin{equation}\n",
    "e^k_i = p^k_i - p^{exact}_i\n",
    "\\end{equation}\n",
    "\n",
    "What if we recast the Poisson equation in terms of a not-perfectly-relaxed $\\bf p^k$?\n",
    "\n",
    "\\begin{equation}\n",
    "A \\bf p^k \\approx b\n",
    "\\end{equation}\n",
    "\n",
    "We can write out the modified Poisson equation like this:\n",
    "\n",
    "\\begin{equation}\n",
    "{\\bf r^k} + A \\bf p^k = b\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steepest Descent:\n",
    "\n",
    "At iteration $0$, we choose an inital guess. Unless we are immensely lucky, it will not satisfy the Poisson equation and we will have,\n",
    "\n",
    "\\begin{equation}\n",
    "{\\bf b}-A{\\bf p}^0={\\bf r}^0\\ne {\\bf 0}\n",
    "\\end{equation}\n",
    "\n",
    "${\\bf r}^0$ is called the initial residual and measures how far we are from satisfying the linear system.\n",
    "\n",
    "Define at each iteration\n",
    "\n",
    "\\begin{equation}\n",
    "{\\bf r}^k={\\bf b}-A{\\bf p}^k\n",
    "\\end{equation}\n",
    "\n",
    "In the method of steepest descent, two choices are made:\n",
    "\n",
    "1. the direction vectors are chosen to be the residuals ${\\bf d}^k = {\\bf r}^k$.\n",
    "2. the length of the jumps are such that the $n+1^{th}$ residual is orthogonal to the $n^{th}$ resuidual.\n",
    "\n",
    "Condition 2 requires that,\n",
    "\n",
    "\\begin{align}\n",
    "{\\bf r}^{k+1}\\cdot {\\bf r}^{k} = 0 \\nonumber \\\\\n",
    "\\Leftrightarrow ({\\bf b}-A{\\bf p}^{k+1}) \\cdot {\\bf r}^{k} = 0 \\nonumber \\\\\n",
    "\\Leftrightarrow ({\\bf b}-A({\\bf p}^{k}+\\alpha {\\bf r}^k)) \\cdot {\\bf r}^{k} = 0 \\nonumber \\\\\n",
    "\\Leftrightarrow ({\\bf r}^k+\\alpha A{\\bf r}^k) \\cdot {\\bf r}^{k} = 0 \\nonumber \\\\\n",
    "\\alpha = \\frac{{\\bf r}^k \\cdot {\\bf r}^k}{A{\\bf r}^k \\cdot {\\bf r}^k}.\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from math import pi\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from laplace_helper import plot_3D, L2_rel_error\n",
    "from cg_helper import poisson_2d, p_analytical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "nx = 101\n",
    "ny = 101\n",
    "xmin = 0\n",
    "xmax = 1\n",
    "ymin = -0.5\n",
    "ymax = 0.5\n",
    "\n",
    "l2_target = 1e-10\n",
    "\n",
    "# Spacing\n",
    "dx = (xmax-xmin)/(nx-1)\n",
    "dy = (ymax-ymin)/(ny-1)\n",
    "\n",
    "# Mesh\n",
    "x  = numpy.linspace(xmin,xmax,nx)\n",
    "y  = numpy.linspace(ymin,ymax,ny)\n",
    "X,Y = numpy.meshgrid(x,y)\n",
    "\n",
    "# Source\n",
    "L = xmax-xmin\n",
    "b = -2*(pi/L)**2*numpy.sin(pi*X/L)*numpy.cos(pi*Y/L)\n",
    "\n",
    "# Initialization\n",
    "p_i  = numpy.zeros((ny,nx))\n",
    "\n",
    "# Analytical solution\n",
    "pan = p_analytical(X,Y,L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution process:\n",
    "    \n",
    "1. Calculate the residual, $\\bf r^k$, which also serves as the direction vector, $\\bf d^k$\n",
    "2. Calculate the step size $\\alpha$\n",
    "3. Update ${\\bf p}^{k+1}={\\bf p}^k + \\alpha {\\bf d}^k$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an equation for the residual above: \n",
    "\\begin{equation}\n",
    "{\\bf r}^k={\\bf b}-A{\\bf p}^k\n",
    "\\end{equation}\n",
    "\n",
    "Laplacian can be discretized:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla^2 p^k = 4p^k_{i,j} - \\left(p^{k}_{i,j-1} + p^k_{i,j+1} + p^{k}_{i-1,j} + p^k_{i+1,j} \\right)\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def steepest_descent_2d(p, b, dx, dy, l2_target):\n",
    "    r  = numpy.zeros((ny,nx)) # residual\n",
    "    Ar  = numpy.zeros((ny,nx)) # to store result of matrix multiplication\n",
    "    \n",
    "    l2_norm = 1\n",
    "    iterations = 0\n",
    "    l2_conv = []\n",
    "    \n",
    "    # Iterations\n",
    "    while l2_norm > l2_target:\n",
    "\n",
    "        pd = p.copy()\n",
    "        \n",
    "        r[1:-1,1:-1] = b[1:-1,1:-1]*dx**2 + 4*pd[1:-1,1:-1] - \\\n",
    "            pd[1:-1,2:] - pd[1:-1,:-2] - pd[2:, 1:-1] - pd[:-2, 1:-1]\n",
    "        \n",
    "        Ar[1:-1,1:-1] = -4*r[1:-1,1:-1]+r[1:-1,2:]+r[1:-1,:-2]+\\\n",
    "            r[2:, 1:-1] + r[:-2, 1:-1]\n",
    "\n",
    "        rho = numpy.sum(r*r)\n",
    "        sigma = numpy.sum(r*Ar)\n",
    "        alpha = rho/sigma\n",
    "\n",
    "        p = pd + alpha*r\n",
    "        \n",
    "        # BCs are automatically enforced\n",
    "        \n",
    "        l2_norm = L2_rel_error(pd,p)\n",
    "        iterations += 1\n",
    "        l2_conv.append(l2_norm)\n",
    "    \n",
    "    print('Number of SD iterations: {0:d}'.format(iterations))\n",
    "    return p, l2_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SD iterations: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.2250762210863876e-05"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p, l2_conv = steepest_descent_2d(p_i.copy(), b, dx, dy, l2_target)\n",
    "L2_rel_error(p, pan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conjugate Gradients\n",
    "\n",
    "reduces number of jumps\n",
    "\n",
    "\\begin{equation}\n",
    "\\alpha = \\frac{{\\bf r}^k \\cdot {\\bf r}^k}{A{\\bf d}^k \\cdot {\\bf d}^k}\n",
    "\\end{equation}\n",
    "\n",
    "direction vectors\n",
    "\n",
    "\\begin{equation}\n",
    "{\\bf d}^{k+1}={\\bf r}^{k+1}+\\beta{\\bf d}^{k}\n",
    "\\end{equation}\n",
    "\n",
    "where: $\\beta = \\frac{{\\bf r}^{k+1} \\cdot {\\bf r}^{k+1}}{{\\bf r}^k \\cdot {\\bf r}^k}$.\n",
    "\n",
    "Implementing Conjugate Gradients\n",
    "\n",
    "update $\\bf p$ according to \n",
    "\n",
    "\\begin{equation}\n",
    "{\\bf p}^{k+1}={\\bf p}^k + \\alpha {\\bf d}^k\n",
    "\\end{equation}\n",
    "\n",
    "Thus, the full set of steps for the method of conjugate gradients is:\n",
    "\n",
    "Calculate ${\\bf d}^0 = {\\bf r}^0$ (just the once), then\n",
    "\n",
    "1. Calculate $\\alpha = \\frac{{\\bf r}^k \\cdot {\\bf r}^k}{A{\\bf d}^k \\cdot {\\bf d}^k}$\n",
    "2. Update ${\\bf p}^{k+1}$\n",
    "3. Calculate ${\\bf r}^{k+1} = {\\bf r}^k - \\alpha A {\\bf d}^k$ $\\ \\ \\ \\ $(see <a href='#references'>Shewchuk (1994)</a>)\n",
    "4. Calculate $\\beta = \\frac{{\\bf r}^{k+1} \\cdot {\\bf r}^{k+1}}{{\\bf r}^k \\cdot {\\bf r}^k}$\n",
    "5. Calculate ${\\bf d}^{k+1}={\\bf r}^{k+1}+\\beta{\\bf d}^{k}$\n",
    "6. Repeat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conjugate_gradient_2d(p, b, dx, dy, l2_target):\n",
    "    r  = numpy.zeros((ny,nx)) # residual\n",
    "    Ad  = numpy.zeros((ny,nx)) # to store result of matrix multiplication \n",
    "    \n",
    "    l2_norm = 1\n",
    "    iterations = 0\n",
    "    l2_conv = []\n",
    "    \n",
    "    # Step-0 We compute the initial residual and \n",
    "    # the first search direction is just this residual\n",
    "    \n",
    "    r[1:-1,1:-1] = b[1:-1,1:-1]*dx**2 + 4*p[1:-1,1:-1] - \\\n",
    "        p[1:-1,2:] - p[1:-1,:-2] - p[2:, 1:-1] - p[:-2, 1:-1]\n",
    "    d = r.copy()\n",
    "    rho = numpy.sum(r*r)\n",
    "    Ad[1:-1,1:-1] = -4*d[1:-1,1:-1]+d[1:-1,2:]+d[1:-1,:-2]+\\\n",
    "        d[2:, 1:-1] + d[:-2, 1:-1]\n",
    "    sigma = numpy.sum(d*Ad)\n",
    "    \n",
    "    # Iterations\n",
    "    while l2_norm > l2_target:\n",
    "\n",
    "        pk = p.copy()\n",
    "        rk = r.copy()\n",
    "        dk = d.copy()\n",
    "        \n",
    "        alpha = rho/sigma\n",
    "\n",
    "        p = pk + alpha*dk\n",
    "        r = rk- alpha*Ad\n",
    "        \n",
    "        rhop1 = numpy.sum(r*r)\n",
    "        beta = rhop1 / rho\n",
    "        rho = rhop1\n",
    "        \n",
    "        d = r + beta*dk\n",
    "        Ad[1:-1,1:-1] = -4*d[1:-1,1:-1] + d[1:-1,2:] + d[1:-1,:-2] + \\\n",
    "            d[2:, 1:-1] + d[:-2, 1:-1]\n",
    "        sigma = numpy.sum(d*Ad)\n",
    "        \n",
    "        # BCs are automatically enforced\n",
    "        \n",
    "        l2_norm = L2_rel_error(pk,p)\n",
    "        iterations += 1\n",
    "        l2_conv.append(l2_norm)\n",
    "    \n",
    "    print('Number of CG iterations: {0:d}'.format(iterations))\n",
    "    return p, l2_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CG iterations: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.2250762210862941e-05"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p, l2_conv = conjugate_gradient_2d(p_i.copy(), b, dx, dy, l2_target)\n",
    "L2_rel_error(p,pan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Jacobi iterations: 31227\n"
     ]
    }
   ],
   "source": [
    "p, l2_conv = poisson_2d(p_i.copy(), b, dx, dy, l2_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complex Poisson Problems:\n",
    "\n",
    "\\begin{equation}\n",
    "b = \\sin\\left(\\frac{\\pi x}{L}\\right) \\cos\\left(\\frac{\\pi y}{L}\\right) + \\sin\\left(\\frac{6\\pi x}{L}\\right) \\cos\\left(\\frac{6\\pi y}{L}\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = (numpy.sin(pi*X/L)*numpy.cos(pi*Y/L)+\n",
    "     numpy.sin(6*pi*X/L)*numpy.sin(6*pi*Y/L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Jacobi iterations: 31226\n",
      "Number of SD iterations: 28671\n",
      "Number of CG iterations: 3\n"
     ]
    }
   ],
   "source": [
    "p, l2_conv = poisson_2d(p_i.copy(), b, dx, dy, l2_target)\n",
    "\n",
    "p, l2_conv = steepest_descent_2d(p_i.copy(), b, dx, dy, l2_target)\n",
    "\n",
    "p, l2_conv = conjugate_gradient_2d(p_i.copy(), b, dx, dy, l2_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
